{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# if you want to load the object #\n",
    "##################################\n",
    "\n",
    "try:\n",
    "    PATH = '/Users/maxwellclarke/Documents/data/fma_metadata/segmented'\n",
    "    os.chdir(PATH)\n",
    "except:\n",
    "    PATH = r'C:\\Users\\james\\Documents\\data\\fma_metadata\\segmented'\n",
    "    os.chdir(PATH)\n",
    "    \n",
    "with open('data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "dfs = data.segmented_dfs # already sorted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tracks', 'genres', 'features', 'echonest'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs['features'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_top\n",
       "Rock                   14182\n",
       "Experimental           10608\n",
       "Electronic              9371\n",
       "Hip-Hop                 3552\n",
       "Folk                    2803\n",
       "Pop                     2332\n",
       "Instrumental            2079\n",
       "International           1389\n",
       "Classical               1230\n",
       "Jazz                     571\n",
       "Old-Time / Historic      554\n",
       "Spoken                   423\n",
       "Country                  194\n",
       "Soul-RnB                 175\n",
       "Blues                    110\n",
       "Easy Listening            24\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tracks.track.groupby('genre_top').count().sort_values('title', ascending=False)['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres to include\n",
    "\n",
    "- Rock\n",
    "- Electronic\n",
    "- Hip-Hop\n",
    "- Folk\n",
    "- Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['spectral_contrast__std', 'spectral_contrast__skew', 'spectral_contrast__mean', 'spectral_contrast__kurtosis', 'spectral_contrast__median', 'spectral_contrast__min', 'spectral_contrast__max', 'tonnetz__std', 'tonnetz__skew', 'tonnetz__mean', 'tonnetz__kurtosis', 'tonnetz__median', 'tonnetz__min', 'tonnetz__max', 'chroma_stft__std', 'chroma_stft__skew', 'chroma_stft__mean', 'chroma_stft__kurtosis', 'chroma_stft__median', 'chroma_stft__min', 'chroma_stft__max', 'mfcc__std', 'mfcc__skew', 'mfcc__mean', 'mfcc__kurtosis', 'mfcc__median', 'mfcc__min', 'mfcc__max', 'spectral_rolloff__std', 'spectral_rolloff__skew', 'spectral_rolloff__mean', 'spectral_rolloff__kurtosis', 'spectral_rolloff__median', 'spectral_rolloff__min', 'spectral_rolloff__max', 'spectral_bandwidth__std', 'spectral_bandwidth__skew', 'spectral_bandwidth__mean', 'spectral_bandwidth__kurtosis', 'spectral_bandwidth__median', 'spectral_bandwidth__min', 'spectral_bandwidth__max', 'spectral_centroid__std', 'spectral_centroid__skew', 'spectral_centroid__mean', 'spectral_centroid__kurtosis', 'spectral_centroid__median', 'spectral_centroid__min', 'spectral_centroid__max', 'rmse__std', 'rmse__skew', 'rmse__mean', 'rmse__kurtosis', 'rmse__median', 'rmse__min', 'rmse__max', 'zcr__std', 'zcr__skew', 'zcr__mean', 'zcr__kurtosis', 'zcr__median', 'zcr__min', 'zcr__max', 'chroma_cqt__std', 'chroma_cqt__skew', 'chroma_cqt__mean', 'chroma_cqt__kurtosis', 'chroma_cqt__median', 'chroma_cqt__min', 'chroma_cqt__max', 'chroma_cens__std', 'chroma_cens__skew', 'chroma_cens__mean', 'chroma_cens__kurtosis', 'chroma_cens__median', 'chroma_cens__min', 'chroma_cens__max'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['features'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the above contain summary statistical information derived from the audio file. For now, I'll only work with mean and standard deviation for category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91214, 149)\n",
      "(25019, 149)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "r = re.compile('.*mean')\n",
    "q = re.compile('.*std')\n",
    "\n",
    "to_concat = [df for key, df in dfs['features'].items() if (bool(r.match(key)) | bool(q.match(key)))] # means and stds dfs\n",
    "\n",
    "df = pd.concat(to_concat +[data.tracks.track[['genre_top']]], axis=1, join='inner')\n",
    "\n",
    "mask = df['genre_top'].isin(['Rock', 'Electronic', 'Hip-Hop', 'Folk', 'Classical'])\n",
    "\n",
    "print(df.shape)\n",
    "df = df[mask]\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how logistic regression performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.drop('genre_top', axis=1)\n",
    "y = df['genre_top']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def test_roc(X, y, est):\n",
    "    \"\"\"Cross validates and evaluates multi-class model.\"\"\"\n",
    "    genres = set(y)\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    classes = set(y)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    roc = {\n",
    "        'test_auc': [],\n",
    "        'train_auc': [],\n",
    "        'test_curve': [],\n",
    "        'train_curve': []\n",
    "    }\n",
    "    \n",
    "    genre_dict = {genre: deepcopy(roc) for genre in genres}\n",
    "\n",
    "    for genre in genres:\n",
    "        targets = (y == genre).astype(int)\n",
    "        \n",
    "        for tr_ix, te_ix in skf.split(X, targets):\n",
    "            \n",
    "\n",
    "            X_train, X_test = X[tr_ix], X[te_ix]\n",
    "            y_train, y_test = targets[tr_ix], targets[te_ix]\n",
    "\n",
    "            est.fit(X_train, y_train)\n",
    "            y_preds = est.predict(X_test)\n",
    "            y_preds_proba_test = est.predict_proba(X_test)\n",
    "            y_preds_proba_train = est.predict_proba(X_train)\n",
    "            \n",
    "            ####\n",
    "            # THE IDEA OF AVERAGING OUT ROC CURVES OVER DIFFERENT FOLDS IS ***MOST QUESTIONABLE***\n",
    "            ####\n",
    "\n",
    "            train_score = roc_auc_score(y_train, y_preds_proba_train[:, 1])\n",
    "            test_score = roc_auc_score(y_test, y_preds_proba_test[:, 1])\n",
    "            genre_dict[genre]['train_auc'].append(train_score)\n",
    "            genre_dict[genre]['test_auc'].append(test_score)\n",
    "            \n",
    "            genre_dict[genre]['test_curve'].append(roc_curve(y_test, y_preds_proba_test[:, 1])[:2])\n",
    "            genre_dict[genre]['train_curve'].append(roc_curve(y_train, y_preds_proba_train[:, 1])[:2])\n",
    "            \n",
    "        # TODO: MAKE ROC PLOT FOR EACH GENRE WITH LEGEND\n",
    "    \n",
    "    return genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pip = Pipeline([\n",
    "    ('std_scl', StandardScaler()),\n",
    "    ('lr', LogisticRegression(solver='lbfgs', max_iter=5000))\n",
    "])\n",
    "\n",
    "scores = test_roc(X_train, y_train, pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical :\t 0.9894\n",
      "Folk :\t\t 0.9204\n",
      "Rock :\t\t 0.9363\n",
      "Electronic :\t 0.9095\n",
      "Hip-Hop :\t 0.9218\n"
     ]
    }
   ],
   "source": [
    "def get_results(scores):\n",
    "    for genre in set(y):\n",
    "        if len(genre) > 5:\n",
    "            print(genre, ':\\t', np.round(np.mean(scores[genre]['train_auc']),4))\n",
    "        else:\n",
    "            print(genre, ':\\t\\t', np.round(np.mean(scores[genre]['train_auc']),4))\n",
    "        \n",
    "get_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "pip = Pipeline([\n",
    "    ('std_scl', StandardScaler()),\n",
    "    ('abc', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "socres = test_roc(X_train, y_train, pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical :\t 0.9958\n",
      "Folk :\t\t 0.9418\n",
      "Rock :\t\t 0.9309\n",
      "Electronic :\t 0.9028\n",
      "Hip-Hop :\t 0.9256\n"
     ]
    }
   ],
   "source": [
    "get_results(socres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost with Logistic Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0cf4df0b91d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgbc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-30cede5483b9>\u001b[0m in \u001b[0;36mtest_roc\u001b[0;34m(X, y, est)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0my_preds_proba_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pip = Pipeline([\n",
    "    ('std_scl', StandardScaler()),\n",
    "    ('gbc', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "gbc_scores = test_roc(X_train, y_train, pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi_class_logisitc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaseEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "def multi_class_logistic_test(X, y, est):\n",
    "    \"\"\"Cross validates and evaluates multi-class model.\"\"\"\n",
    "    genres = set(y)\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    classes = set(y)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    scores = {\n",
    "        'train': [],\n",
    "        'test': []\n",
    "    }\n",
    "    \n",
    "    estimators = []\n",
    "    for tr_ix, te_ix in skf.split(X, y):\n",
    "        esti = deepcopy(est)\n",
    "\n",
    "        X_train, X_test = X[tr_ix], X[te_ix]\n",
    "        y_train, y_test = y[tr_ix], y[te_ix]\n",
    "\n",
    "        esti.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_preds = esti.predict(X_train)\n",
    "        y_test_preds = esti.predict(X_test)\n",
    "        y_preds_proba_test = esti.predict_proba(X_test)\n",
    "        y_preds_proba_train = esti.predict_proba(X_train)\n",
    "\n",
    "        scores['train'].append(accuracy_score(y_train, y_train_preds))\n",
    "        scores['test'].append(accuracy_score(y_test, y_test_preds))\n",
    "            \n",
    "        estimators.append(esti)\n",
    "    \n",
    "    return scores, estimators\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "scores, estimators = multi_class_logistic_test(X_train, y_train, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators[0].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.044861</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                01        01 genre_top\n",
       "track_id                              \n",
       "2         0.085629  0.061448   Hip-Hop\n",
       "3         0.084578  0.069330   Hip-Hop\n",
       "5         0.053114  0.044861   Hip-Hop\n",
       "10        0.077515  0.040800       Pop\n",
       "20        0.047225  0.030993       NaN"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = dfs['tracks']['track']['genre_top']\n",
    "simple_feats = pd.concat([dfs['features']['zcr__mean'], dfs['features']['zcr__std'], targets], axis=1, join='inner')\n",
    "simple_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (simple_feats['genre_top'].isin(['Rock', 'Electronic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_feats = simple_feats[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(simple_feats.drop('genre_top', axis=1), simple_feats['genre_top'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('simple_model.pickle', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"16\" halign=\"left\">01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_top</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>7718.0</td>\n",
       "      <td>0.053568</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.034787</td>\n",
       "      <td>0.049146</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.462462</td>\n",
       "      <td>7718.0</td>\n",
       "      <td>0.049832</td>\n",
       "      <td>0.027971</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>0.044816</td>\n",
       "      <td>0.06335</td>\n",
       "      <td>0.264326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>11129.0</td>\n",
       "      <td>0.058187</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.043274</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.069570</td>\n",
       "      <td>0.550677</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.017574</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.021154</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.03817</td>\n",
       "      <td>0.178451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 01                                                    \\\n",
       "              count      mean       std       min       25%       50%   \n",
       "genre_top                                                               \n",
       "Electronic   7718.0  0.053568  0.027640  0.002491  0.034787  0.049146   \n",
       "Rock        11129.0  0.058187  0.022993  0.002735  0.043274  0.056026   \n",
       "\n",
       "                                                                       \\\n",
       "                 75%       max    count      mean       std       min   \n",
       "genre_top                                                               \n",
       "Electronic  0.067003  0.462462   7718.0  0.049832  0.027971  0.001702   \n",
       "Rock        0.069570  0.550677  11129.0  0.032351  0.017574  0.001785   \n",
       "\n",
       "                                                   \n",
       "                 25%       50%      75%       max  \n",
       "genre_top                                          \n",
       "Electronic  0.030712  0.044816  0.06335  0.264326  \n",
       "Rock        0.021154  0.027751  0.03817  0.178451  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_feats.groupby('genre_top').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rock'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(simple_feats.drop('genre_top', axis=1).values[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17.08494855, -29.92371724]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# MODIFYING ABOVE TO COMBINE PREDICTION OF ALL\n",
    "#############\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "def multi_test(X, y, est):\n",
    "    \"\"\"Cross validates and evaluates multi-class model.\"\"\"\n",
    "    genres = set(y)\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    classes = list(set(y))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    scores = {\n",
    "        'train': [],\n",
    "        'test': []\n",
    "    }\n",
    "        \n",
    "    estimators = {}\n",
    "        \n",
    "    for tr_ix, te_ix in skf.split(X, y):\n",
    "        \n",
    "\n",
    "        X_train, X_test = X[tr_ix], X[te_ix]\n",
    "        y_train, y_test = y[tr_ix], y[te_ix]\n",
    "        \n",
    "        for genre in genres:\n",
    "            \n",
    "            targets = (y_train == genre).astype(int)\n",
    "\n",
    "            \n",
    "            estimators[genre] = clone(est)\n",
    "\n",
    "            estimators[genre].fit(X_train, targets)\n",
    "            \n",
    "#             y_preds = estimators[genre].predict(X_test)\n",
    "#             y_preds_proba_test = estimators[genre].predict_proba(X_test)\n",
    "#             y_preds_proba_train = estimators[genre].predict_proba(X_train)\n",
    "\n",
    "            ####\n",
    "            # THE IDEA OF AVERAGING OUT ROC CURVES OVER DIFFERENT FOLDS IS ***MOST QUESTIONABLE***\n",
    "            ####\n",
    "        \n",
    "        probas = np.array([estimators[genre].predict_proba(X_train) for genre in genres])\n",
    "        print(X_train.shape)\n",
    "        print(probas.shape)\n",
    "        probas = probas[:,:,0].reshape(-1, 5)\n",
    "        print(probas.shape)\n",
    "        \n",
    "        preds = np.array([classes[np.argmax(prob)] for prob in probas])\n",
    "        print(preds.shape)\n",
    "        print(y_train.shape)\n",
    "        \n",
    "        scores['train'].append(accuracy_score(y_train, preds))\n",
    "        \n",
    "        probas = np.array([estimators[genre].predict_proba(X_test) for genre in genres])\n",
    "        probas = probas[:,:,0].reshape(-1, 5)\n",
    "        preds = np.array([classes[np.argmax(prob)] for prob in probas])\n",
    "        \n",
    "        scores['test'].append(accuracy_score(y_test, preds))\n",
    "        \n",
    "    return scores\n",
    "            \n",
    "\n",
    "#         train_score = roc_auc_score(y_train, y_preds_proba_train[:, 1])\n",
    "#         test_score = roc_auc_score(y_test, y_preds_proba_test[:, 1])\n",
    "#         genre_dict[genre]['train_auc'].append(train_score)\n",
    "#         genre_dict[genre]['test_auc'].append(test_score)\n",
    "\n",
    "            \n",
    "        # TODO: MAKE ROC PLOT FOR EACH GENRE WITH LEGEND\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16010, 148)\n",
      "(5, 16010, 2)\n",
      "(16010, 5)\n",
      "(16010,)\n",
      "(16010,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16011, 148)\n",
      "(5, 16011, 2)\n",
      "(16011, 5)\n",
      "(16011,)\n",
      "(16011,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16011, 148)\n",
      "(5, 16011, 2)\n",
      "(16011, 5)\n",
      "(16011,)\n",
      "(16011,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16013, 148)\n",
      "(5, 16013, 2)\n",
      "(16013, 5)\n",
      "(16013,)\n",
      "(16013,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16015, 148)\n",
      "(5, 16015, 2)\n",
      "(16015, 5)\n",
      "(16015,)\n",
      "(16015,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "scores = multi_test(X_train, y_train, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [0.1971267957526546,\n",
       "  0.1985509961901193,\n",
       "  0.20029979389169947,\n",
       "  0.19640292262536688,\n",
       "  0.20068685607243208],\n",
       " 'test': [0.1990012484394507,\n",
       "  0.2012987012987013,\n",
       "  0.18856143856143856,\n",
       "  0.20514742628685656,\n",
       "  0.2045]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores # something is rotten in the state of denmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
